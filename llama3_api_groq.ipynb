{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I believe you meant to ask about the importance of \"genetics\" rather than \"genai\".\n",
      "\n",
      "Genetics is the study of how traits are passed down from one generation to the next. The importance of genetics cannot be overstated, as it plays a crucial role in our understanding of many biological processes and has numerous applications in various fields. Here are some reasons why genetics is important:\n",
      "\n",
      "1. **Understand disease susceptibility**: Genetics helps us understand the causes of many diseases, such as genetic disorders, and can inform strategies for prevention and treatment.\n",
      "2. **Development and evolution**: Genetics explains how species adapt to their environments and evolve over time, which is essential for understanding the diversity of life on Earth.\n",
      "3. **Cancer research**: Genetic mutations linked to cancer can help researchers develop targeted therapies and improve treatment options.\n",
      "4. **Genetic counseling**: Understanding genetic traits can help families make informed decisions about prenatal testing, family planning, and reproductive choices.\n",
      "5. **Forensic science**: Genetic analysis is used in forensic science to identify individuals, link crime scenes to suspects, and solve crimes.\n",
      "6. **Agriculture and food production**: Genetics is used to develop crop and animal breeds with desirable traits, improving food security and reducing the environmental impact of farming.\n",
      "7. **Personalized medicine**: Genetic testing can help individuals understand their genetic predispositions to certain diseases, allowing for personalized interventions and treatments.\n",
      "8. **Ethnology and anthropology**: Genetic research can provide insights into human migration patterns, population history, and cultural transmission.\n",
      "9. **Biotechnology**: Genetic engineering has led to numerous innovations in biotechnology, such as the development of genetically modified organisms (GMOs) and gene therapy.\n",
      "10. **Basic scientific research**: The study of genetics has led to fundamental discoveries in biology, ecosystems, and evolution, driving our understanding of the natural world and our place within it.\n",
      "\n",
      "In conclusion, genetics is a crucial field of study that has far-reaching implications for our understanding of life, medicine, and the environment. Its importance cannot be overstated, and continued research in genetics will likely lead to significant breakthroughs and improvements in various fields.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of genai\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "# Initialize the Groq client\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "def ask_question(question, model=\"llama3-8b-8192\"):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "# Main loop to ask questions\n",
    "while True:\n",
    "    question = input(\"Enter your question (or type 'exit' to quit): \")\n",
    "    if question.lower() == 'exit':\n",
    "        break\n",
    "    answer = ask_question(question)\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your question (press Enter on an empty line to finish, type 'exit' to quit): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: i want some information about some products listed in amazon like product name, price and rating so can you provide me with that ?\n",
      "Answer: I'd be happy to help you with that. However, I'm a large language model, I don't have direct access to Amazon's database, but I can assist you in finding the information you're looking for.\n",
      "\n",
      "Please provide me with the product names or ASINs (Amazon Standard Identification Number) of the products you're interested in, and I'll do my best to fetch the following information:\n",
      "\n",
      "1. Product Name\n",
      "2. Current Price\n",
      "3. Customer Rating (out of 5 stars)\n",
      "\n",
      "Please note that prices and ratings may change over time, so this information may not be up-to-date. Additionally, Amazon's policies prohibit scraping or scraping content from their website, so I'll need to rely on Amazon's public APIs or cached versions of product pages.\n",
      "\n",
      "Please provide the product names or ASINs, and I'll do my best to retrieve the information you're looking for.\n",
      "Enter your question (press Enter on an empty line to finish, type 'exit' to quit): \n",
      "\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "# Initialize the Groq client\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "def ask_question(question, model=\"llama3-8b-8192\"):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "def get_multiline_input(prompt):\n",
    "    print(prompt)\n",
    "    buffer = []\n",
    "    while True:\n",
    "        line = input()\n",
    "        if line.strip().lower() == 'exit':\n",
    "            return 'exit'\n",
    "        if line == \"\":\n",
    "            break\n",
    "        buffer.append(line)\n",
    "    return \"\\n\".join(buffer)\n",
    "\n",
    "# Main loop to ask questions\n",
    "try:\n",
    "    while True:\n",
    "        question = get_multiline_input(\"Enter your question (press Enter on an empty line to finish, type 'exit' to quit): \")\n",
    "        if question.strip().lower() == 'exit':\n",
    "            break\n",
    "        print(f\"Question: {question}\")\n",
    "        answer = ask_question(question)\n",
    "        print(f\"Answer: {answer}\")\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    print(\"\\nExiting...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve the webpage. Status code: 503\n",
      "An error occurred: Failed to retrieve the webpage after several attempts\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "from scrapegraphai.graphs import SearchGraph\n",
    "\n",
    "# Apply nest_asyncio to handle nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Define the configuration for the graph\n",
    "graph_config = {\n",
    "    \"llm\": {\n",
    "        \"model\": \"groq/llama3-8b-8192\",\n",
    "        \"api_key\": os.environ.get(\"GROQ_API_KEY\"),  # Fetch the API key from environment variables\n",
    "        \"temperature\": 0\n",
    "    },\n",
    "    \"embeddings\": {\n",
    "        \"model\": \"ollama/nomic-embed-text\",\n",
    "        \"base_url\": \"http://localhost:11434\",  # Ensure this URL is correct and the service is running\n",
    "    },\n",
    "    \"max_results\": 5,\n",
    "}\n",
    "\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept-Language': 'en-US, en;q=0.5'\n",
    "}\n",
    "\n",
    "# Function to extract Product Title\n",
    "def get_title(soup):\n",
    "    try:\n",
    "        title = soup.find(\"span\", attrs={\"id\": 'productTitle'})\n",
    "        title_value = title.text\n",
    "        title_string = title_value.strip()\n",
    "    except AttributeError:\n",
    "        title_string = \"\"\n",
    "    return title_string\n",
    "\n",
    "# Function to extract Product Price\n",
    "def get_price(soup):\n",
    "    try:\n",
    "        price = soup.find(\"span\", attrs={'id': 'priceblock_ourprice'}).string.strip()\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            price = soup.find(\"span\", attrs={'id': 'priceblock_dealprice'}).string.strip()\n",
    "        except:\n",
    "            price = \"\"\n",
    "    return price\n",
    "\n",
    "# Function to extract Product Rating\n",
    "def get_rating(soup):\n",
    "    try:\n",
    "        rating = soup.find(\"i\", attrs={'class': 'a-icon a-icon-star a-star-4-5'}).string.strip()\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            rating = soup.find(\"span\", attrs={'class': 'a-icon-alt'}).string.strip()\n",
    "        except:\n",
    "            rating = \"\"\n",
    "    return rating\n",
    "\n",
    "# Function to extract Number of User Reviews\n",
    "def get_review_count(soup):\n",
    "    try:\n",
    "        review_count = soup.find(\"span\", attrs={'id': 'acrCustomerReviewText'}).string.strip()\n",
    "    except AttributeError:\n",
    "        review_count = \"\"\n",
    "    return review_count\n",
    "\n",
    "# Function to extract Availability Status\n",
    "def get_availability(soup):\n",
    "    try:\n",
    "        available = soup.find(\"div\", attrs={'id': 'availability'})\n",
    "        available = available.find(\"span\").string.strip()\n",
    "    except AttributeError:\n",
    "        available = \"Not Available\"\n",
    "    return available\n",
    "\n",
    "# Function to extract Product Image URL\n",
    "def get_image_url(soup):\n",
    "    try:\n",
    "        image_container = soup.find(\"div\", attrs={'class': 'imgTagWrapper'})\n",
    "        img_tag = image_container.find('img')\n",
    "        if img_tag and 'src' in img_tag.attrs:\n",
    "            image_url = img_tag['src']\n",
    "        else:\n",
    "            image_url = \"\"\n",
    "    except AttributeError:\n",
    "        image_url = \"\"\n",
    "    return image_url\n",
    "\n",
    "# Save the webpage content to an HTML file with retry mechanism\n",
    "def save_webpage_to_html(url, filename, retries=3, delay=5):\n",
    "    for attempt in range(retries):\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        if response.status_code == 200:\n",
    "            with open(filename, 'w', encoding='utf-8') as file:\n",
    "                file.write(response.text)\n",
    "            return\n",
    "        elif response.status_code == 429:\n",
    "            print(f\"Rate limited. Retrying in {delay} seconds...\")\n",
    "            time.sleep(delay)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "            break\n",
    "    raise Exception(\"Failed to retrieve the webpage after several attempts\")\n",
    "\n",
    "# Parse the HTML file and extract information\n",
    "def extract_information_from_html(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    products = []\n",
    "    for product in soup.select('div.s-main-slot div.s-result-item'):  # Adjust the selector based on the actual HTML structure\n",
    "        title = get_title(product)\n",
    "        price = get_price(product)\n",
    "        rating = get_rating(product)\n",
    "        review_count = get_review_count(product)\n",
    "        availability = get_availability(product)\n",
    "        image_url = get_image_url(product)\n",
    "        \n",
    "        if title:\n",
    "            products.append({\n",
    "                'name': title,\n",
    "                'price': price,\n",
    "                'rating': rating,\n",
    "                'reviews': review_count,\n",
    "                'availability': availability,\n",
    "                'image_url': image_url\n",
    "            })\n",
    "    \n",
    "    return products\n",
    "\n",
    "async def run_search_graph():\n",
    "    try:\n",
    "        # Save the webpage content to an HTML file\n",
    "        url = \"https://www.amazon.com/s?k=iphone+15+pro+max&ref=nb_sb_noss_1\"\n",
    "        filename = \"webpage.html\"\n",
    "        save_webpage_to_html(url, filename)\n",
    "        \n",
    "        # Extract information from the saved HTML file\n",
    "        products = extract_information_from_html(filename)\n",
    "        df = pd.DataFrame(products)\n",
    "        print(df)\n",
    "    except requests.exceptions.RequestException as req_e:\n",
    "        print(f\"Request error: {req_e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Main function to run the async task\n",
    "async def main():\n",
    "    await run_search_graph()\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        if loop.is_running():\n",
    "            # If loop is already running, use nest_asyncio to run the coroutine\n",
    "            nest_asyncio.apply()\n",
    "            loop.run_until_complete(main())\n",
    "        else:\n",
    "            loop.run_until_complete(main())\n",
    "    except RuntimeError as e:\n",
    "        print(f\"RuntimeError: {e}\")\n",
    "        # Create a new event loop if necessary\n",
    "        new_loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(new_loop)\n",
    "        new_loop.run_until_complete(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
