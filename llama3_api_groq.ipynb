{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "# Initialize the Groq client\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "def ask_question(question, model=\"llama3-8b-8192\"):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "# Main loop to ask questions\n",
    "while True:\n",
    "    question = input(\"Enter your question (or type 'exit' to quit): \")\n",
    "    if question.lower() == 'exit':\n",
    "        break\n",
    "    answer = ask_question(question)\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your question (press Enter on an empty line to finish, type 'exit' to quit): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: i want some information about some products listed in amazon like product name, price and rating so can you provide me with that ?\n",
      "Answer: I'd be happy to help you with that. However, I'm a large language model, I don't have direct access to Amazon's database, but I can assist you in finding the information you're looking for.\n",
      "\n",
      "Please provide me with the product names or ASINs (Amazon Standard Identification Number) of the products you're interested in, and I'll do my best to fetch the following information:\n",
      "\n",
      "1. Product Name\n",
      "2. Current Price\n",
      "3. Customer Rating (out of 5 stars)\n",
      "\n",
      "Please note that prices and ratings may change over time, so this information may not be up-to-date. Additionally, Amazon's policies prohibit scraping or scraping content from their website, so I'll need to rely on Amazon's public APIs or cached versions of product pages.\n",
      "\n",
      "Please provide the product names or ASINs, and I'll do my best to retrieve the information you're looking for.\n",
      "Enter your question (press Enter on an empty line to finish, type 'exit' to quit): \n",
      "\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "# Initialize the Groq client\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "def ask_question(question, model=\"llama3-8b-8192\"):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "def get_multiline_input(prompt):\n",
    "    print(prompt)\n",
    "    buffer = []\n",
    "    while True:\n",
    "        line = input()\n",
    "        if line.strip().lower() == 'exit':\n",
    "            return 'exit'\n",
    "        if line == \"\":\n",
    "            break\n",
    "        buffer.append(line)\n",
    "    return \"\\n\".join(buffer)\n",
    "\n",
    "# Main loop to ask questions\n",
    "try:\n",
    "    while True:\n",
    "        question = get_multiline_input(\"Enter your question (press Enter on an empty line to finish, type 'exit' to quit): \")\n",
    "        if question.strip().lower() == 'exit':\n",
    "            break\n",
    "        print(f\"Question: {question}\")\n",
    "        answer = ask_question(question)\n",
    "        print(f\"Answer: {answer}\")\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    print(\"\\nExiting...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
